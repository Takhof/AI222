import sys
import streamlit as st
from transformers import BertTokenizer
from tensorflow import keras
import numpy as np
from transformers import TFBertModel
import os
import pandas as pd
import json
from pathlib import Path
import gdown

print(sys.executable)


# q/a dataã®CSV
data_path = Path("qa_data.csv")
if not data_path.exists():
    df = pd.DataFrame(columns=["question", "answer"])
    df.to_csv(data_path, index=False, encoding="utf-8-sig")


# ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®æº–å‚™
model_path = "ramen_retriever.h5"
if not os.path.exists(model_path):
    file_id = "1CmJuR_H2eFBaGY88XdPdrLcoYcvqwt7T"  # è‡ªåˆ†ã®ãƒ•ã‚¡ã‚¤ãƒ«IDã«ã—ã¦ã­
    gdown.download(f"https://drive.google.com/uc?id={file_id}", model_path, quiet=False)
model = keras.models.load_model(model_path, custom_objects={"TFBertModel": TFBertModel})
tokenizer = BertTokenizer.from_pretrained("cl-tohoku/bert-base-japanese")



# æ¨è«–ã®ãŸã‚ã®é–¢æ•°
def tokenize_pair(q, a, max_len=64):
    inputs = tokenizer(q, a, padding='max_length', truncation=True, max_length=max_len, return_tensors="tf")
    return inputs['input_ids'][0], inputs['attention_mask'][0]

def get_best_answer(question, candidates):
    input_ids_list = []
    attention_masks_list = []
    for ans in candidates:
        ids, mask = tokenize_pair(question, ans)
        input_ids_list.append(ids)
        attention_masks_list.append(mask)
    input_ids = np.stack(input_ids_list)
    attention_masks = np.stack(attention_masks_list)
    preds = model.predict([input_ids, attention_masks])
    best_idx = np.argmax(preds)
    return candidates[best_idx], float(preds[best_idx][0])

# å€™è£œæ–‡
candidates = [
    "ã‚¹ãƒ¼ãƒ—ã¯è±šéª¨ã‚„é¶ã‚¬ãƒ©ã‚’é•·æ™‚é–“ç…®è¾¼ã‚“ã§ä½œã‚Šã¾ã™ã€‚",
    "å‘³å™Œãƒ©ãƒ¼ãƒ¡ãƒ³ã¯åŒ—æµ·é“ã§ç”Ÿã¾ã‚ŒãŸãƒ©ãƒ¼ãƒ¡ãƒ³ã§ã™ã€‚",
    "ãƒãƒ£ãƒ¼ã‚·ãƒ¥ãƒ¼ã¯è±šãƒãƒ©è‚‰ã§ä½œã‚‹ãƒˆãƒƒãƒ”ãƒ³ã‚°ã§ã™ã€‚",
    "ã¡ã¢ã‚Œéººã¯ã‚¹ãƒ¼ãƒ—ãŒã‚ˆãçµ¡ã‚€ç‰¹å¾´ãŒã‚ã‚Šã¾ã™ã€‚"
]

# Streamlit UI
st.title("ğŸœãƒ©ãƒ¼ãƒ¡ãƒ³ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«AI")
st.markdown("### æ°—ã«ãªã‚‹ãƒ©ãƒ¼ãƒ¡ãƒ³ã®ã“ã¨ã€ãªã‚“ã§ã‚‚èã„ã¦ã­â™ª")

user_question = st.text_input("ğŸ” è³ªå•ã‚’å…¥åŠ›ã—ã¦ã­")

if user_question:
    answer, score = get_best_answer(user_question, candidates)
    st.markdown("### ğŸ’¡ ç­”ãˆ")
    st.success(f"{answer}")
    st.markdown(f"ã‚¹ã‚³ã‚¢ï¼š`{score:.4f}`")



st.markdown("### âœï¸ å›ç­”ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ")

new_q = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ã­ï¼ˆè¿½åŠ ç”¨ï¼‰", key="add_q")
new_a = st.text_input("ãã®ç­”ãˆã‚’å…¥åŠ›ã—ã¦ã­", key="add_a")

if st.button("ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹"):
    if new_q and new_a:
        df = pd.read_csv(data_path)
        df = pd.concat([df, pd.DataFrame([{"question": new_q, "answer": new_a}])], ignore_index=True)
        df.to_csv(data_path, index=False, encoding="utf-8-sig")
        st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ãŸã‚ˆï¼ã‚ã‚ŠãŒã¨ã†")
    else:
        st.warning("âš ï¸ è³ªå•ã¨ç­”ãˆã€ã©ã£ã¡ã‚‚ã„ã‚Œã¦ã­ã€œï¼")


if st.button("ä»Šã¾ã§ã®è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã‚‹"):
    df = pd.read_csv(data_path)
    if df.empty:
        st.info("ã¾ã è¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ãªã„ã¿ãŸã„ã€œğŸ’¤")
    else:
        for i, row in df.iterrows():
            st.markdown(f"**{i+1}. Q:** {row['question']}")
            st.markdown(f"A: {row['answer']}")

