# ğŸœ Ramen Retriever AI

æ—¥æœ¬èªBERTãƒ™ãƒ¼ã‚¹ã§æ§‹ç¯‰ã—ãŸã€ãƒ©ãƒ¼ãƒ¡ãƒ³å°‚é–€ã®è³ªå•å¿œç­”ãƒ¢ãƒ‡ãƒ«ï¼  
è³ªå•ã«å¯¾ã—ã¦ã€ã‚‚ã£ã¨ã‚‚é©åˆ‡ãªãƒ©ãƒ¼ãƒ¡ãƒ³æƒ…å ±ã‚’é«˜ç²¾åº¦ã«ãƒãƒƒãƒãƒ³ã‚°ã™ã‚‹AIã§ã™âœ¨  

---

## ğŸš€ æ©Ÿèƒ½æ¦‚è¦

- ğŸ¤– [`cl-tohoku/bert-base-japanese`](https://huggingface.co/cl-tohoku/bert-base-japanese) ã«ã‚ˆã‚‹ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
- ğŸ’¡ è³ªå•ã¨å›ç­”ã®ãƒšã‚¢ã§ãƒã‚¤ãƒŠãƒªåˆ†é¡ï¼ˆæ­£è§£ or ä¸æ­£è§£ï¼‰
- ğŸ” æ–°ã—ã„Q&Aã‚’è¿½åŠ ã—ã¦å†å­¦ç¿’ï¼ˆFine-tuningï¼‰ãŒå¯èƒ½
- ğŸ§  Streamlitã‚„APIã¸ã®å¿œç”¨ã‚‚ç°¡å˜ï¼

---

## ğŸ§¾ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

ramen-retriever-ai/
â”œâ”€â”€ model_creator.py # æœ€åˆã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ model_finetune.py # è¿½åŠ å­¦ç¿’ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ retriever_qa.json # è³ªå•ãƒ»æ­£è§£ãƒ»èª¤ç­”ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
â”œâ”€â”€ qa_data.json # è¿½åŠ å­¦ç¿’ç”¨ã®Q&Aãƒ‡ãƒ¼ã‚¿ï¼ˆquestion/answerå½¢å¼ï¼‰
â”œâ”€â”€ ramen_model.h5 # å­¦ç¿’æ¸ˆã¿Kerasãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ requirements.txt # ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
â””â”€â”€ README.md # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
---

## ğŸ› ï¸ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ–¹æ³•

### 1. Pythonç’°å¢ƒã‚’ç”¨æ„

```bash
python -m venv venv
source venv/bin/activate  # Windowsã®æ–¹ã¯ venv\Scripts\activate
pip install -r requirements.txt


2. å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
shell
Copy
Edit
tensorflow>=2.11
transformers>=4.30
numpy


ğŸ§ª ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆåˆå›ï¼‰
retriever_qa.json ã«ä»¥ä¸‹ã®å½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ï¼š

json
Copy
Edit
[
  {
    "question": "ãƒ©ãƒ¼ãƒ¡ãƒ³ã®ã‚¹ãƒ¼ãƒ—ã®ç¨®é¡ã¯ï¼Ÿ",
    "positive": "é†¤æ²¹ã€å‘³å™Œã€å¡©ã€ã¨ã‚“ã“ã¤ãªã©ãŒã‚ã‚Šã¾ã™ã€‚",
    "negatives": [
      "ã‚µãƒƒã‚«ãƒ¼ã¯11äººã§ã‚„ã‚Šã¾ã™ã€‚",
      "ãƒšãƒ³ã‚®ãƒ³ã¯é£›ã¹ã¾ã›ã‚“ã€‚"
    ]
  }
]
ãã®ã‚ã¨ä»¥ä¸‹ã‚’å®Ÿè¡Œï¼š

bash
Copy
Edit
python model_creator.py
ãƒ¢ãƒ‡ãƒ«ã¯ ramen_model.h5 ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚

ğŸ” è¿½åŠ å­¦ç¿’ï¼ˆFine-tuningï¼‰
è¿½åŠ ãƒ‡ãƒ¼ã‚¿ï¼ˆqa_data.jsonï¼‰ã‚’ä»¥ä¸‹ã®å½¢å¼ã§ä½œæˆï¼š

[
  {
    "question": "å‘³å™Œãƒ©ãƒ¼ãƒ¡ãƒ³ã®ç‰¹å¾´ã¯ï¼Ÿ",
    "answer": "æ¿ƒåšãªå‘³å™Œã ã‚ŒãŒç‰¹å¾´ã§ã™ã€‚"
  }
]
ä»¥ä¸‹ã‚’å®Ÿè¡Œï¼š

bash
Copy
Edit
python model_finetune.py
å†å­¦ç¿’å¾Œã®ãƒ¢ãƒ‡ãƒ«ã¯ "ramen_model_finetuned.h5" ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã™ã€‚

ğŸ§ª æ¨è«–ï¼ˆã‚¤ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ï¼‰
æ¨è«–ç”¨ã‚³ãƒ¼ãƒ‰ä¾‹ï¼ˆStreamlitã‚„APIã«å¿œç”¨å¯èƒ½ï¼‰ï¼š

python
Copy
Edit
from transformers import BertTokenizer
import tensorflow as tf

tokenizer = BertTokenizer.from_pretrained("cl-tohoku/bert-base-japanese")
model = tf.keras.models.load_model("ramen_model_finetuned.h5")

def predict_score(question, answer):
    inputs = tokenizer(question, answer, padding="max_length", max_length=64, truncation=True, return_tensors="tf")
    pred = model.predict([inputs["input_ids"], inputs["attention_mask"]])
    return float(pred[0][0])


ğŸ§¼ .gitignore ã«å…¥ã‚Œã¦ãŠãã¨ä¾¿åˆ©ãªã‚‚ã®
markdown
Copy
Edit
__pycache__/
*.pyc
*.h5
*.keras
.env
.vscode/
.idea/


ğŸ“œ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
MIT License

ğŸ¥ Special Thanks
ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ãƒ©ãƒ¼ãƒ¡ãƒ³ã‚’æ„›ã™ã‚‹ã™ã¹ã¦ã®AIã¨äººé–“ãŸã¡ã«æ§ã’ã¾ã™ã€‚
ãƒ©ãƒ¼ãƒ¡ãƒ³ã¯ä¸–ç•Œã‚’æ•‘ã†â€¦ã‹ã‚‚ï¼Ÿ ğŸœğŸ’•
